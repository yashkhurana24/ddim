{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[],"source":["import torch\n","import torchvision\n","from torchvision.datasets import ImageFolder\n","import torch.nn as nn\n","import torchvision.transforms as tt\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","from torch.utils.data import DataLoader\n","%matplotlib inline\n","from torchvision.utils import save_image\n","from torchvision.utils import make_grid\n","from tqdm.notebook import tqdm\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["data_path = \"128\"\n","image_size = 256\n","batch_size = 16\n","normstats = (0.,0.,0.),(1.,1.,1.)\n","transforms = tt.Compose([tt.Resize(image_size),#resize to make things uniform\n","                        tt.CenterCrop(image_size),#cropping to the center to avoid distortion\n","                        tt.ToTensor(),#to a tensor\n","                        tt.Normalize(*normstats)#normalizing in order to increase effectiveness of our GAN\n","                        ])\n","dataset = ImageFolder(data_path, transform = transforms)\n","img, _ = dataset[0]\n","plt.imshow(img.permute((1,2,0)))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def denorm(img_tensors):\n","    return img_tensors * normstats[1][0] + normstats[0][0]\n","\n","def show_batch(dl):#just to show one batch of our data\n","    for img, _ in dl:\n","        fig, ax = plt.subplots(figsize=(8,8))\n","        ax.set_xticks([]);ax.set_yticks([])\n","        ax.imshow(torchvision.utils.make_grid(img[:64],nrow = 8).permute(1,2,0))\n","        break\n","\n","def show_images(images):\n","    fig, ax = plt.subplots(figsize=(8,8))\n","    ax.set_xticks([]),ax.set_yticks([])\n","    ax.imshow(torchvision.utils.make_grid(denorm(images.detach()[:64]),nrow = 8).permute(1,2,0))\n","\n","dataload = DataLoader(dataset,batch_size,num_workers = 4,shuffle = True, pin_memory=True)#makes our data into batches\n","show_batch(dataload)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def find_default_device():\n","    if torch.cuda.is_available():\n","        return torch.device(\"cuda\")\n","    else:\n","        return torch.device('cpu')\n","    \n","device = find_default_device()\n","print(device)\n","\n","def to_device(data,device):\n","    if isinstance(data,(list,tuple)):\n","        return [to_device(x,device) for x in data]\n","    else:\n","        return data.to(device, non_blocking=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class DataloaderDeviced():\n","    def __init__(self,data,device):\n","        self.data = data\n","        self.device = device\n","    def __iter__(self):\n","        for b in self.data:\n","            yield to_device(b,self.device)\n","    def __len__(self):\n","        return len(self.data)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["dataload = DataloaderDeviced(dataload,device)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["descriminator = nn.Sequential(\n","    #input size being of 3 channels, 256x256\n","    nn.Conv2d(3, 32 ,kernel_size = 3, stride = 2, padding = 1, bias = False),\n","    nn.BatchNorm2d(32),\n","    nn.LeakyReLU(0.1, inplace=True),\n","    #output size being of 32 channels, 128x128\n","    \n","    nn.Conv2d(32,64,kernel_size = 4, stride = 2, padding = 1, bias = False),\n","    nn.BatchNorm2d(64),\n","    nn.LeakyReLU(0.1, inplace=True),\n","    #out 64x64x64\n","    \n","    nn.Conv2d(64,128,kernel_size = 4, stride = 2, padding = 1, bias = False),\n","    nn.BatchNorm2d(128),\n","    nn.LeakyReLU(0.1, inplace = True),\n","    #out 128x32x32\n","    \n","    nn.Conv2d(128,256,kernel_size = 4, stride = 2, padding = 1, bias = False),\n","    nn.BatchNorm2d(256),\n","    nn.LeakyReLU(0.1,inplace = True),\n","    #out 256x16x16\n","    \n","    nn.Conv2d(256,512, kernel_size = 4, stride = 2, padding = 1, bias = False),\n","    nn.BatchNorm2d(512),\n","    nn.LeakyReLU(0.1, inplace = True),\n","    #out 512x8x8\n","    \n","    nn.Conv2d(512,1024, kernel_size = 4, stride = 2, padding = 1, bias = False),\n","    nn.BatchNorm2d(1024),\n","    nn.LeakyReLU(0.1,inplace = True),\n","    #out 1024x4x4\n","    \n","    nn.Conv2d(1024,1,kernel_size = 4,stride = 1, padding = 0, bias = False),\n","    #out 1x1x1\n","    \n","    nn.Flatten(),\n","    nn.Sigmoid(),\n","    #final activation for T/F\n",")\n","\n","#descriminator.load_state_dict(torch.load(\"../input/weights/discweights4.pth\"))\n","descriminator = to_device(descriminator,device)\n","descriminator"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["latent_sz = 64"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["generator = nn.Sequential(\n","    #latent in 128x1x1\n","    nn.ConvTranspose2d(128,1024,kernel_size = 4, stride = 1, padding = 0, bias = False),\n","    nn.BatchNorm2d(1024),\n","    nn.LeakyReLU(0.1, inplace=True),\n","    #out 1024x4x4\n","    \n","    nn.ConvTranspose2d(1024,512,kernel_size = 4, stride = 2, padding = 1, bias = False),\n","    nn.BatchNorm2d(512),\n","    nn.LeakyReLU(0.1, inplace=True),\n","    #out 512x8x8\n","    \n","    nn.ConvTranspose2d(512,256,kernel_size = 4, stride = 2, padding = 1, bias = False),\n","    nn.BatchNorm2d(256),\n","    nn.LeakyReLU(0.1, inplace=True),\n","    #out 256x16x16\n","    \n","    nn.ConvTranspose2d(256,128,kernel_size = 4, stride = 2, padding = 1, bias = False),\n","    nn.BatchNorm2d(128),\n","    nn.LeakyReLU(0.1, inplace=True),\n","    #out 128x32x32\n","    \n","    nn.ConvTranspose2d(128,64,kernel_size = 4, stride = 2, padding = 1, bias = False),\n","    nn.BatchNorm2d(64),\n","    nn.LeakyReLU(0.1, inplace=True),\n","    #out 64x64x64\n","    \n","    nn.ConvTranspose2d(64,32,kernel_size = 4, stride = 2, padding = 1, bias = False),\n","    nn.BatchNorm2d(32),\n","    nn.LeakyReLU(0.1, inplace=True),\n","    #out 32x128x128\n","    \n","    nn.ConvTranspose2d(32,3,kernel_size = 4, stride = 2, padding = 1, bias = False),\n","    nn.Tanh()\n","    #out 3x256x256\n","    \n",")\n","#generator.load_state_dict(torch.load(\"../input/weights/genweights4.pth\"))\n","generator"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["xb = torch.randn(batch_size,latent_sz,1,1,)\n","fake_images = generator(xb)\n","show_images(fake_images)\n","generator = to_device(generator,device)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def train_discriminator(real_images,opt_d):\n","    \n","    opt_d.zero_grad()\n","    real_preds = descriminator(real_images)\n","    real_targets = torch.ones(real_images.size(0),1,device = device)\n","    real_loss = F.binary_cross_entropy(real_preds,real_targets)\n","    real_score = torch.mean(real_preds).item()\n","    \n","    latent = torch.randn(batch_size,latent_sz,1,1, device = device)\n","    fake_images = generator(latent)\n","    \n","    fake_preds = descriminator(fake_images)\n","    fake_targets = torch.zeros(fake_images.size(0),1,device = device)\n","    fake_loss = F.binary_cross_entropy(fake_preds,fake_targets)\n","    fake_score = torch.mean(fake_preds).item()\n","    \n","    loss = fake_loss+real_loss\n","    loss.backward()\n","    opt_d.step()\n","    \n","    return loss.item(),real_score,fake_score"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def train_generator(opt_g):\n","    opt_g.zero_grad()\n","    latent = torch.randn(batch_size,latent_sz, 1,1, device = device)\n","    images = generator(latent)\n","    \n","    targets = torch.ones(batch_size,1,device = device)\n","    score = descriminator(images)\n","    loss = F.binary_cross_entropy(score,targets)\n","    \n","    loss.backward()\n","    opt_g.step()\n","    \n","    return loss.item()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["savedir = \"model_outputs/gan\"\n","os.makedirs(savedir, exist_ok = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def save_samples(index, latent_tensors, show=True):\n","    fake_images = generator(latent_tensors)\n","    fake_fname = 'generated-images-{0:0=4d}e1.png'.format(index+90)\n","    save_image(denorm(fake_images), os.path.join(savedir, fake_fname), nrow=8)\n","    print('Saving', fake_fname)\n","    if show:\n","        fig, ax = plt.subplots(figsize=(8, 8))\n","        ax.set_xticks([]); ax.set_yticks([])\n","        ax.imshow(make_grid(fake_images.cpu().detach(), nrow=8).permute(1, 2, 0))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["torch.manual_seed(64)\n","fixed_latent = torch.randn(batch_size, latent_sz, 1, 1, device=device)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["save_samples(0,fixed_latent)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def fit(epochs, lr, start_idx = 1):\n","    loss_d =[]\n","    loss_g = []\n","    real_scores = []\n","    fake_scores = []\n","    \n","    opt_d = torch.optim.Adam(descriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n","    opt_g = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n","    \n","    for epoch in range(epochs):\n","        for img, _ in tqdm(dataload):\n","            \n","            loss, real_score, fake_score = train_discriminator(img, opt_d)\n","            lossg = train_generator(opt_g)\n","            \n","        loss_d.append(loss)\n","        loss_g.append(lossg)\n","        real_scores.append(real_score)\n","        fake_scores.append(fake_score)\n","        \n","        print(\"Epoch [{}/{}], loss_g: {:.4f}, loss_d: {:.4f}, real_score: {:.4f}, fake_score: {:.4f}\".format(\n","            epoch+1, epochs, loss, lossg, real_score, fake_score))\n","        \n","        save_samples(epoch+start_idx, fixed_latent, show=False)\n","        \n","    return loss_g,loss_d,real_scores,fake_scores"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["lr = 5e-4\n","epochs = 2\n","history = fit(epochs,lr)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["torch.save(generator.state_dict(),\"genweights4.pth\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["torch.save(descriminator.state_dict(),\"discweights4.pth\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["torch.manual_seed(94)\n","latent_test = torch.randn(1,latent_sz,1,1,device=device)\n","image = generator(latent_test)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["image=to_device(image, torch.device(\"cpu\"))\n","b=image[0].permute(1,2,0).detach().numpy()\n","b.shape"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":4}
